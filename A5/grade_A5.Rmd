---
title: "Tucker_A5"
author: "Michael Tucker"
date: "2020-02-14"
output: 
  html_document: 
    code_folding: hide
    theme: cerulean
    toc: true
    smooth_scroll: true
    toc_depth: 3
    toc_float: true
    number_sections: false
---

<style type="text/css">  
/* Note: CSS uses C-style commenting. */
h1.title{font-size:22px; text-align:center;}
h4.author{font-size:16px; text-align:center;}
h4.date{font-size:16px; text-align:center;}
body{ /* Normal  */ font-size: 13px}
td {  /* Table   */ font-size: 12px}
h1 { /* Header 1 */ font-size: 16px}
h2 { /* Header 2 */ font-size: 14px}
h3 { /* Header 3 */ font-size: 12px}
.math{ font-size: 10pt;}
.hi{ /* hanging indents */ 
    padding-left:22px; 
    text-indent:-22px;
}
blockquote {  
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 12px;
    border-left: 5px solid #eee;
}
code.r{ /* code */ 
       font-size: 12px;
}
pre{/*preformatted text*/ 
    font-size: 12px;
}
p.caption {/* figure captions */ 
    font-size: 0.9em;
    font-style: italic; 
} 
</style>

```{r setup, echo=FALSE}
rm(list=ls()) # clean up
library(knitr)
gr <- (1+sqrt(5))/2 # golden ratio, for figures
opts_chunk$set(comment="  ",
               collapse=TRUE, 
               #echo=FALSE,
               fig.asp=1/gr,
               dev="png"
               )
options(digits=3)
```  

**Score:** 62/70    

General:  

- Nicely formatted code!  

- It IS is hard to switch between 1- and 0-based indexing. Glad you are getting the knack.   

- When using inline code in narrative I like to give the desired number a descriptive name in the chunk, then use that name inline. Otherwise, my long inline code makes the narrative awkward to read in the Rmd. 

Ex 5.0:  7/10  

- If the posterior and prior come from the same family of distributions, the gamma for example, then the prior is said to be _conjugate_. The terminology is unfortunate, I think, and the subject is best understood by showing examples.  

- "Joint parameter space" is just another way of saying that there is more than one parameter in the model.  

Ex 5.05: 5/10. First part not done.    

Ex 5.1.1:  15/15. Good variable names, and nice clear code.      

Ex 5.1.2:  5/5.  One of us is wrong, but I cannot see whether the error is yours or mine.   

Ex 5.1.3:  10/10. Code is very nice, so I'm overlooking the missing table. See the solution for how easy it is to do.      

Ex 5.1.4:  5/5. One of us is wrong.    

Ex 5.4:   0/15. Not done.  

Ex 5.5 (extra credit):   10/10. You did not do anything wrong here. The difference arises because of the finite number of samples.     

Ex 5.6 (extra credit):   5/15. Your `dmb()` does not agree with `dbeta()` because you used a sum instead of an integral. (If you had multiplied your sum it by `dx` it would have been close.) Notice the difference between the y-axis and x-axis in the left panel of your figure. 

# Introduction  
This assignment is based mostly on Chapter 5 of our text. Ex 5.1.1-4 treats a dichotomous classifier problem (Is it A, or is it not?). Ex 5.6 is a warmup for the Gibbs Sampler.  

# Fun fact  
R Markdown isn't limited to the R engine. The following code engines can be used by putting their name where you usually put the `r` in the chunk header: `r names(knitr::knit_engines$get())`. [GNU Octave](https://www.gnu.org/software/octave/) is a freeware version of `Matlab`. [Go](https://en.wikipedia.org/wiki/Go_(programming_language)), designed at Google, is a faster, safer version of `C` with some features of `C++`. [Julia](https://en.wikipedia.org/wiki/Julia_(programming_language)) is a recently developed high-performance language for numerical analysis. The [Rcpp package](https://www.tandfonline.com/doi/abs/10.1080/00031305.2017.1375990?journalCode=utas20) offers "a seamless integration of R and C++."  

# Ex 5.0  
(not in text) (10 points)   
List the technical terms you encountered in this chapter, with a '?' to indicate those you have not encountered before. Look up at least **two** of the terms that are new to you, and give definitions that makes sense to you. Give the definitions as numbered footnotes---see the [R Markdown 
Cheat Sheet](https://rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf) or [R Markdown Reference Guide](https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf).  

# Solution 5.0  

* **conjugate prior**^[I don't fully understand this, a conjugate prior is said to be prior and posterior distributions that come from the same _family_ but I'm not sure what that means. Continuous vs. discreet maybe?]
* **joint parameter space**^[The parameter space allowed by two correlated variables]

# Exercise 5.05  
(not in text, 10 points)
This exercise is a preparation for Exercise 5.1.  

## Ex 5.05(a)  
Read the Wikipedia entry for [prosecutor's fallacy](https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy). Would you have sided with the prosecutor in the Sally Clark case (be honest)? Does this entry increase your estimation of the importance of Bayesian thinking in basic problems such as Exercise 5.1 (page 118) in our textbook? Give a concise mnemonic formula for the prosecutors fallacy in the form Pr(a|b)=Pr(b|a).  

## Solution 5.0.5(a)    
(Put your narrative here.)   

## Ex 5.0.5(b)  
Glance at the Wikipedia entry for [Sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity), and page 103 of our text, then group the following terms into exactly four classes, such that the terms in each class have the same meaning: specificity, fall-out, true negative rate, sensitivity, false alarm rate, true positive rate, false alarm rate, hit rate, false negative rate, false positive rate. It is not necessary to name the classes; just group the terms.

## Solution 5.0.5(b)  

* Class 1:  
  + sensitivity
  + true positive rate
  + hit rate
* Class 2:  
  + specificity
  + true negative rate
* Class 3:  
  + false positive rate
  + fall-out
  + false alarm rate
* Class 4:  
  + false negative rate


# Ex 5.1.1  
(Based loosely on Ex 5.1 of our text, page 118) (15 points)  

## Preamble  

The nomenclature of testing can be confusing, so when confronted with a problem of this type it is good to seek help from the sum rule. Using + and - to denote positive and negative test results, and D (for diseased) and H (for healthy) to denote the absence and presence of disease, we use the sum rule to write:

    Pr(+|H) + Pr(-|H) = 1. In other words, fpr + tnr = 1.
    Pr(+|D) + Pr(-|D) = 1. In other words, tpr + fnr = 1. 

The true positive rate (tpr) is often called the _sensitivity_ and the true negative rate (tnr) is often called the _specificity_, but we will use tpr and tnr.  

## The task  

a. Write a function `ppD(tr, tpr, fpr, prior)` that computes the posterior probability of disease given:  

+ `tr`, the test result (1 if the test indicates disease is present, 0 if not), 
+ `tpr`, the true positive rate (sensitivity),  
+ `fpr`, the false positive rate (1 minus the specificity)   
+ `prior`, the prior probability of disease.

  Give `tr` a default value of 1.  

b. Use your function to solve the disease problem on page 103 of our text. That is, use your function to calculate the probability of disease given a positive test result for a test with true positive rate 99%, false positive rate 5% and prior probability 0.1%. Put your answer in a sentence of narrative using inline code.   

# Solution 5.1.1  

```{r sol5.1.1, collapse=FALSE}

ppD = function(tr, tpr, fpr, prior) {
  # adpated from DBDA pg 104
  #calculate marginal probs
  posTest = tpr*prior + fpr*(1-prior)
  negTest = (1-tpr)*prior + (1-fpr)*(1-prior)
  if (tr == 1){
    # test is pos
    post = tpr*prior / posTest
  }
  else {
    # test is neg
    post = fpr*prior/negTest
  }
  return(post)
}

#given values
tpr = 0.99
fpr = 0.05
prior = 0.001

```

Assuming Joe Schmo (randomly) comes into the Queen's Urgent Care and wants to be tested for _RareDisease120783D_. The test comes back positives, should Joe Schmo be worried and/or committed to the local CDC quarantine facility? The test itself has a true positive rate `r tpr`, false positive rate of `r fpr`, and only `r prior` fraction of the population has _RareDisease120783D_. With these values in-hand, we can determine the updated _posterior_ probability that Joe Schmo does in fact have _RareDisease120783D_: `r round(ppD(1, tpr, fpr, prior)*100., 2)`%. So, still not much to be concerned about. 

# Ex 5.1.2    
(a continuation of the previous problem) (5 points)  
Use your function from the previous exercise to compute the probability of disease if the patient is tested twice, once with a positive result and once with a negative result. Give your answer as a sentence of narrative using inline code. **Hint:** Use the posterior from the previous exercise as your prior for this one.

# Solution 5.1.2  

```{r sol5.1.2}

#assume first test is positive, if first test is neg prob not testing twice
first_test = ppD(1, 0.99, 0.05, 0.001)
second_test = ppD(0, 0.99, 0.05, first_test)
```


```{r sol5.1.2testing, eval=FALSE}
#actually write a function to wrap both
composite_ppD = function(tr1, tr2, tpr=0.99, fpr=0.05, prior=0.001){
  first_result = ppD(tr1, tpr, fpr, prior)
  second_result = ppD(tr2, tpr, fpr, first_result)
  return(second_result)
}

# just having fun with dataframes
df = data.frame('test1'=c(0,0,1,1), 'test2'=c(0,1,0,1))

# didnt work
#df$results = apply(df, c(1,2), composite_ppD)
results = vector(length = 4)

# not sure how to iterate through a double list, this can be done in python like:
#result = [function(a,b) for a,b in zip(list_a, list_b)]
# but brute force works as well

for (i in c(1,2,3,4)){
  results[[i]] = composite_ppD(df$test1[i], df$test2[i])*100.
}
df$results=results

print(df)
```

Joe Schmo tested positive the first time, so we want a second test to confirm. Since the first test was in fact positive, this is our updated prior for the second test, as the 0.1% prior no longer applies to Joe Schmo (as he is no longer random). The second test comes back negative, but we have to also consider the non-zero false negative rate. Therefore, the final probability that Jow Schmo has _RareDisease120783D_ is `r round(second_test*100., 3)`%, a low probability indeed. 


# Ex 5.1.3  
(case of multiple tests of different types) (10 points)  
Generalize your `ppD()` to a function `ppDm()` that handles multiple tests in a single call. For `ppDm()` the arguments `tr`, `tpr` and `fpr` will usually be vectors of the same length, but write it to cover the case of multiple identical tests where `tr` has length greater than 1 but `tpr` and `fpr` have length 1. Use your `ppDm()` to find the posterior probability of disease when five tests are given. Use the following prior, test results, and test characteristics.  

    prior = 9.4/100 (the U.S. prevalence of diabetes)
    tr  = c( 1,  0,  1,  1,  1)
    tpr = c(99, 85, 93, 92, 75)/100 
    fpr = c( 5, 15, 10, 12, 18)/100

Display these data in a table using `knitr::kable()` with an appropriate caption that starts with **Table 5.1.3.**  (I used a line of inline code to do this.)  

# Solution 5.1.3 


```{r sol5.1.3}
#still not comfortable with how r handles and accesses arrays,
#so the following code is a wee bit ugly, brute-forced the array
#iteration


###### 
# took me wayyy too long to realize the error in my previous 
# hw assignments is b/c r used 1-based indexing instead of 
# 0-based
######

ppDm = function(tr, tpr, fpr, prior){
  p = prior
  if ( (length(tr) == length(tpr)) && ( length(tr)== length(fpr)) ){
    for (i in 1:length(tr)){
      p = ppD(tr[i], tpr[i], fpr[i], p)
    }
  }
  else if (length(tr) > 1){
    for (i in 1:length(tr)){
      p = ppD(tr[i], tpr, fpr, p)
    }
  }
  else {
    p = ppD(tr, tpr, fpr, prior)
  }
  return(p)
}

#first case
tr1 = c(1,0,1,1,1)
tpr1 = c(99,85,93,92,75)/100.
fpr1 = c(5,15,10,12,18)/100.
prior = 9.4/100.
post1 = ppDm(tr1, tpr1, fpr1, prior)

#second case
# just made up some numbers
tr2 = c(1,0,1,1,1)
tpr2 = 0.85
fpr2 = 0.25
post2 = ppDm(tr2, tpr2, fpr2, prior)



```


For the first case (multiple tests each with different `tpr` and `fpr` rates), we find the final probability is `r round(post1*100., 3)`% for the values given above and for the second case (single test with mutiple iterations) is `r round(post2*100., 3)`%.

(didnt have time to make a nice table, sorry)

# Ex 5.1.4  
Use your function `ppDm()` to check your result in Ex 5.1.1 (single test with positive result) and Ex 5.1.2 (repeated test with one positive and one negative result).  

# Solution 5.1.4  


```{r sol5.1.4}

check1 = ppDm(1, 0.99, 0.05, 0.001)
check2 = ppDm(c(1,0), 0.99, 0.05, 0.001)

```

Just to check our code, we find that `ppDm` returns `r round(check1*100, 3)`% for the single positive case and `ppDm` returns `r round(check2*100., 3)`% for the pos->neg case. 


# Ex 5.4  
(based loosely on Ex 5.4, on page 120 of our text) (15 points)  
Write a chunk that makes a 3 by 2 matrix of plots in the style of Figures 5.1-3 in our text. In the left column, use a vague prior and an informative Bernoulli likelihood (`Z=10`, `N=40`); in the right column use an informative prior and a vague Bernoulli likelihood (`Z=1`, `N=4`). Don't bother putting the HDIs on the plots. Use Kruschke's `BernGridExample.R` and `BernGrid.R` for inspiration, but do not `source()` any of his scripts.  

## Suggestions    

1. Use $\theta$ in your axis labels but save typing by using `x` instead of `theta` in your code.  

2. Use Kruschke's "triangle" function `y <- pmin(x,1-x)^a` or R's `dbeta(x,shape1,shape2)` for your priors.  

3. Scale your likelihood by using `y <- 0.45*y/max(y)`.  

4. Scale your prior and posterior by using either `y <- y/sum(y)` (the [Dirac comb](https://en.wikipedia.org/wiki/Dirac_comb) approximation used by Kruschke) or `y <- y/trap(x,y)` (the piecewise linear approximation) where `trap()` is a function that returns the integral of `y` over its whole domain, calculated by the [trapezoidal-rule](https://en.wikipedia.org/wiki/Trapezoidal_rule):  

```
trap <- function(x,y)  # integral of y from x[1] to x[length(x)]  
          sum( diff(x)*0.5*( y[-1] + y[-length(y)] ) )  
```

# Solution 5.4  

ran out of time, skipped

# Ex 5.5  
(not in text) (10 points)  

This problem will give you a bit of practise using samples, something we spoke of in our first few meetings: (a) Use `rbeta()` to generate 2,000 samples of $\theta$ from the beta distribution with shape parameters `a=2` and `b=3`; use `set.seed(123)` in your chunk to ensure that we all use the same set of pseudo-random numbers and thus get the same answer. (b) Use your samples to calculate $\Pr(\theta < 0.75\, \vert\, \theta > 0.5)$. (c) Check your result using `pbeta()`. Give your answers in narrative using inline code.   

# Solution 5.5  

```{r sol5.5}

# a) make samples
set.seed(123)
Nsample = 2000
a = 2
b = 3
samples = rbeta(Nsample, a, b)
hist(samples, 25,plot=TRUE)


#b) find samples between 0.5 and 0.75
idx0 = samples > 0.5
idx1 = samples > 0.5 & samples < 0.75
frac1 = sum(idx1) / sum(idx0)

#c) check against pbeta

# i think pbeta returns cdf up until x
# via bayes rule, P(A|B) = P(B|A)*P(A)/P(B)
# P(B|A) = P(theta > 0.5 | theta < 0.75) = pbeta(0.75,a,b) - pbeta(0.5,a,b)
P_BA = 1.0 - ( pbeta(0.5, a, b) / pbeta(0.75, a, b) )

# P(A) = P(theta > 0.5) = 1.0 - P(theta < 0.5)
P_A = 1.0 - pbeta(0.5, a, b)

# P(B) = P(theta < 0.75) = pbeta(0.75, a, b)
P_B = pbeta(0.75, a, b)

#put it all together
P_AB = P_BA * P_B / P_A

```
Looking at the histogram of sampled values, my value for $P(\theta<0.75|\theta>0.5) = $`r round(frac1, 3)` seems reasonable but trying to check against `pbeta` gives me a vlue of `r P_AB`... not sure where my error is.


# Ex 5.6  

(Not in text) (15 points)  
In order to code a Gibbs sampler (GS) you must be able to make any positive 1-D function into a PDF and sample from it. (As you will learn in class, and in Chapter 7 of our text, the Gibbs sampler works by taking a draw from each parameter, holding the other parameters temporarily fixed. The multidimensional posterior thus become a 1-D function of the parameter currently being "visited".) This exercise is an introduction to GS coding.  

Suppose the `(d,p,q,r)beta` quartet of functions is not supplied by R and you have to write your own. This exercise is to write `dmb()`, your own version of `dbeta()`. Think "d-my-beta". In the next assignment, we'll complete the quartet by writing `pmb()`, `qmb()` and `rmb()`.   

Write `dmb(x, a=1, b=1, Ni=301)` which makes $f(\theta,a,b)=\theta^{a-1}(1-\theta)^{b-1}$ into a PDF using `Ni` points to compute the integral. Give a partial check of your work by graphing `dmb(x,a=2,b=4,N=201)` against `dbeta(x, shape1=2, shape2=4)` for `x <- seq(0,1,len=101)`, fitting a line with `lm()` and making a histogram of the residuals. Put the two plots side by side in the same figure with the histogram in the right panel.   

**Hints:** A PDF has to integrate to 1, so divide $f(\theta,a,b)$ by its integral from 0 to 1 to make it a PDF. You can use `integrate()` if you like, but remember that in MCMC you might call this function 100,000 times; for greater speed you might consider using the trapezoidal rule: `sum( diff(xi)*0.5*(fi[-1] + fi[-Ni]) )`, in which `Ni` is the number of points used to compute `xi` and `fi`; do not confuse the `xi` with the `dmb()` argument `x`. In the left panel of your figure use `xlab=bquote("dbeta("*a==.(a)*","~b==.(b)*")")` and `ylab=bquote("dmb("*a==.(a)*","~b==.(b)*")")`.    

## Solution 5.6  

```{r sol5.6part1}

# not sure why you need Ni...

trap <- function(x,y)  # integral of y from x[1] to x[length(x)]  
          sum( diff(x)*0.5*( y[-1] + y[-length(y)] ) )  


dmb = function(x, a=1,b=1,Ni=301) {
  a0 = a-1
  b0 = b-1
  res = (x**a0) * ((1-x)**b0)
  res = res / sum(res)
  return(res)
}

x = seq(0, 1, by=0.01)
a = 2
b = 4

myvals = dmb(x, a, b)
rvals = dbeta(x, a, b)
fit = lm(myvals ~ rvals)


plot(rvals, myvals)
hist(fit$residuals)
```


My version seems to work, but I dont use `Ni` at all... not sure what I'm missing...
