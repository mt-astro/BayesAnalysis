---
title: "Frazer_A5"
author: "Neil Frazer"
date: "2020-02-14"
output: 
  html_document: 
    code_folding: hide
    theme: cerulean
    toc: true
    smooth_scroll: true
    toc_depth: 3
    toc_float: true
    number_sections: false
---

<style type="text/css">  
/* Note: CSS uses C-style commenting. */
h1.title{font-size:22px; text-align:center;}
h4.author{font-size:16px; text-align:center;}
h4.date{font-size:16px; text-align:center;}
body{ /* Normal  */ font-size: 13px}
td {  /* Table   */ font-size: 12px}
h1 { /* Header 1 */ font-size: 16px}
h2 { /* Header 2 */ font-size: 14px}
h3 { /* Header 3 */ font-size: 12px}
.math{ font-size: 10pt;}
.hi{ /* hanging indents */ 
    padding-left:22px; 
    text-indent:-22px;
}
blockquote {  
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 12px;
    border-left: 5px solid #eee;
}
code.r{ /* code */ 
       font-size: 12px;
}
pre{/*preformatted text*/ 
    font-size: 12px;
}
p.caption {/* figure captions */ 
    font-size: 0.9em;
    font-style: italic; 
} 
</style>

```{r setup, echo=FALSE}
rm(list=ls()) # clean up
library(knitr)
gr <- (1+sqrt(5))/2 # golden ratio, for figures
opts_chunk$set(comment="  ",
               collapse=TRUE, 
               #echo=FALSE,
               fig.asp=1/gr,
               dev="png"
               )
options(digits=3)
```  

# Introduction  
This assignment is based mostly on Chapter 5 of our text. 

# Fun fact  
R Markdown isn't limited to the R engine. The following code engines can be used by putting their name where you usually put the `r` in the chunk header: `r names(knitr::knit_engines$get())`. [GNU Octave](https://www.gnu.org/software/octave/) is a freeware version of `Matlab`. [Go](https://en.wikipedia.org/wiki/Go_(programming_language)), designed at Google, is a faster, safer version of `C` with some features of `C++`. [Julia](https://en.wikipedia.org/wiki/Julia_(programming_language)) is a recently developed high-performance language for numerical analysis. The [Rcpp package](https://www.tandfonline.com/doi/abs/10.1080/00031305.2017.1375990?journalCode=utas20) offers "a seamless integration of R and C++."  

# Ex 5.0  
(not in text) (10 points)   
List the technical terms you encountered in this chapter, with a '?' to indicate those you have not encountered before. Look up at least **two** of the terms that are new to you, and give definitions that makes sense to you. Give the definitions as numbered footnotes---see the [R Markdown 
Cheat Sheet](https://rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf) or [R Markdown Reference Guide](https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf).      

# Solution 5.0  
(Notice that this paragraph uses footnotes for the definitions. When you click on a footnote in the html you are taken there, and clicking on the curved arrow will take you back.) The technical terms I noticed are: frequentist, _F_-ratio, Bayes rule, prior (distribution), posterior (distribution), two-way discrete table, row attribute, column attribute, hit rate (for a diagnostic test), false alarm rate, base rate, row marginal, column marginal, likelihood, marginal likelihood, prior predictive, evidence,^[The number you get when you substitute the actual data values into the prior predictive is called the evidence.] data order invariance, independence,^[Spatiotemporal data points are seldom independent, which is why time series analysis and spatial analysis require special techniques] bias, categorical (data), Bernoulli distribution, sample size, candidate value (of a parameter), variational approximation, exhaustive summation. 

# Exercise 5.05  
(not in text, 10 points)
This exercise is a preparation for Exercise 5.1.  

## Ex 5.05(a)  
Read the Wikipedia entry for [prosecutor's fallacy](https://en.wikipedia.org/wiki/Prosecutor%27s_fallacy). Would you have sided with the prosecutor in the Sally Clark case (be honest)? Does this entry increase your estimation of the importance of Bayesian thinking in basic problems such as Exercise 5.1 (page 118) in our textbook? Give a concise mnemonic formula for the prosecutors fallacy in the form Pr(a|b)=Pr(b|a).  

## Solution 5.0.5(a)    
I certainly would have sided with the prosecutor. In fact I recall reading about the case as it happened and thinking that Ms. Gates must certainly have been guilty. Shame on me. A concise mnemonic for the _prosecutor's fallacy_ is Pr(I|E)=Pr(E|I) in which I stands for innocence and E stands for evidence.  

## Ex 5.0.5(b)  
Glance at the Wikipedia entry for [Sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity), and page 103 of our text, then group the following terms into exactly four classes, such that the terms in each class have the same meaning: specificity, fall-out, true negative rate, sensitivity, false alarm rate, true positive rate, false alarm rate, hit rate, false negative rate, false positive rate. It is not necessary to name the classes; just group the terms.

## Solution 5.0.5(b)  
The four classes are  

- true positive rate, hit rate, sensitivity 
- false positive rate, false alarm rate, fall-out
- true negative rate, specificity
- false negative rate  

# Ex 5.1.1  
(Based loosely on Ex 5.1 of our text, page 118) (15 points)  

## Preamble  

The nomenclature of testing can be confusing, so when confronted with a problem of this type it is good to seek help from the sum rule. Using + and - to denote positive and negative test results, and D (for diseased) and H (for healthy) to denote the presence and absence of disease, we use the sum rule to write:

    Pr(+|H) + Pr(-|H) = 1. In other words, fpr + tnr = 1.
    Pr(+|D) + Pr(-|D) = 1. In other words, tpr + fnr = 1. 

The true positive rate (tpr) is often called the _sensitivity_ and the true negative rate (tnr) is often called the _specificity_, but we will use tpr and tnr.  

## The task  

a. Write a function `ppD(tr, tpr, fpr, prior)` that computes the posterior probability of disease given:  

+ `tr`, the test result (1 if the test indicates disease is present, 0 if not), 
+ `tpr`, the true positive rate (sensitivity),  
+ `fpr`, the false positive rate (1 minus the specificity)   
+ `prior`, the prior probability of disease, i.e., the prevalence of the disease in the population of interest.  

  Give `tr` a default value of 1.  

b. Use your function to solve the disease problem on page 103 of our text. That is, use your function to calculate the probability of disease given a positive test result for a test with true positive rate 99%, false positive rate 5% and prior probability 0.1%. Put your answer in a sentence of narrative using inline code.   

# Solution 5.1.1  
```{r ex5.1.1}
ppD <- function(tr=1, tpr, fpr, prior) {
  ## argument list
  # tr: the test result, 1(0) is +(-)ve
  # tpr: true positive rate (sensitivity) of the test
  # fpr: false positive rate (1-specificity)
  # prior: prior probability of the disease
  
  ## matrix of conditional probabilities Pr(T|D)
  # row 1 is positive test result
  # row 2 is negative test result
  # col 1 is presence of disease
  # col 2 is absence of disease
  PrTgD      <- matrix(rep(0,4), nrow=2)
  PrTgD[1,1] <- tpr     # true positive rate
  PrTgD[1,2] <- fpr     # false positive rate
  PrTgD[2,1] <- 1 - tpr # false negative rate
  PrTgD[2,2] <- 1 - fpr # true negative rate
  
  ir <- ifelse(tr != 0, 1, 2) # row index
  
  post <- PrTgD[ir, 1]*prior / 
            ( PrTgD[ir, 1]*prior + PrTgD[ir, 2]*(1-prior) )
  return(post)
}

## Now do the problem on page 103.
tr <- 1
tpr <- 0.99
fpr <- 0.05
prior <- 0.001
post1 <- ppD(tr=tr, tpr=tpr, fpr=fpr, prior=prior) 
```  

For this problem we considered a test with true positive rate `r tpr*100`% and false positive rate `r fpr*100`% for a disease with prior probability `r prior*100`%. Given a `r ifelse(tr, "positive", "negative")` test result, the posterior probability of disease is `r post1*100`%. My result is in agreement with the result on page 104 of our text, so my code is at least not obviously wrong.   

# Ex 5.1.2    
(a continuation of the previous problem) (5 points)  
Use your function from the previous exercise to compute the probability of disease if the patient is tested twice, once with a positive result and once with a negative result. Give your answer as a sentence of narrative using inline code. **Hint:** Use the posterior from the previous exercise as your prior for this one.  

# Solution 5.1.2  
```{r ex5.1.2}
post2 <- ppD(tr=0, tpr=tpr, fpr=fpr, prior=post1)
```  

The probability of disease given one positive test result and one negative test result is `r post2*100`%.  

# Ex 5.1.3  
(case of multiple tests of different types) (10 points)  
Generalize your `ppD()` to a function `ppDm()` that handles multiple tests in a single call. For `ppDm()` the arguments `tr`, `tpr` and `fpr` will usually be vectors of the same length, but write it to cover the case of multiple identical tests where `tr` has length greater than 1 but `tpr` and `fpr` have length 1. Use your `ppDm()` to find the posterior probability of disease when five tests are given. Use the following prior, test results, and test characteristics.  

    prior = 9.4/100 (the U.S. prevalence of diabetes)
    tr  = c( 1,  0,  1,  1,  1)
    tpr = c(99, 85, 93, 92, 75)/100 
    fpr = c( 5, 15, 10, 12, 18)/100

Display these data in a table using `knitr::kable()` with an appropriate caption that starts with **Table 5.1.3.**  (I used a line of inline code to do this.)  

# Solution 5.1.3 

One strategy for this problem is to note that the tests are independent, and then make the obvious extension to the two-test Bayes rule formula at the top of page 108 in our text. Another strategy is to use the single-test formula in a for-loop with the posterior from the first test becoming the prior of the second test, and so forth. My strategy was to make `ppDm()` recursive.  

Note that when my `ppDm()` calls itself, it refers to itself as `Recall()` instead of `ppDm()`. This usage ensures that if I assign `ppDm` to something else, it will still work. Remember that functions in R are _first class functions_; i.e., they are objects like everything else. After creating `ppDm()` I could, if I wished, type, `PPdM <- ppDm; rm(ppDm)` and `PPdM()` would work just like `ppDm()` used to work.   

```{r ex5.1.3}
ppDm <- function(tr=1, tpr, fpr, prior) {
  ## argument list
  # tr: vector of 1's and 0's. 1's indicate presence of disease
  # tpr: TPR should be length 1 or length(tr). Not checked!
  # fpr: FPR should be length 1 or length(tr). Not checked!
  # prior: prior probability of disease
  
  ltr <- length(tr)
  if (ltr > 1) {
    if (length(tpr) == 1) tpr <- rep(tpr, ltr)
    if (length(fpr) == 1) fpr <- rep(fpr, ltr)
  }
  
  PrTgD      <- matrix(rep(0,4), nrow=2)
  PrTgD[1,1] <- tpr[1]     # true positive rate
  PrTgD[1,2] <- fpr[1]     # false positive rate
  PrTgD[2,1] <- 1 - tpr[1] # false negative rate
  PrTgD[2,2] <- 1 - fpr[1] # true negative rate
  
  ir <- ifelse(tr[1] != 0, 1, 2) # make row index
  post <- PrTgD[ir, 1]*prior / 
            ( PrTgD[ir, 1]*prior + PrTgD[ir, 2]*(1-prior) )
      
  if (ltr == 1) {
    return(post)
  } else {
    tr  <-  tr[-1]
    tpr <- tpr[-1]
    fpr <- fpr[-1]
    Recall(tr, tpr, fpr, post) # call itself
  }
}

## Now use the function  
prior <- 9.4/100
tr  <-  c( 1,  0,  1,  1,  1)
tpr <-  c(99, 85, 93, 92, 75)/100 
fpr <-  c( 5, 15, 10, 12, 18)/100
post <- ppDm(tr, tpr, fpr, prior)

## make data frame for display
TR <- ifelse(tr, "+ve", "-ve")
df <- data.frame("Test result"=TR, TPR=tpr, FPR=fpr)
```  

For this problem we considered a battery of five tests with results as given in the following table. The prior probability is `r prior*100`% and the posterior probabilty is `r post*100`%.  

`r kable(df, caption=paste0("**Table 5.1.3.** A battery of five tests with various true positive rates and false positive rates. The posterior probability of disease is ", signif(post*100, 4), "%."))`  

# Ex 5.1.4  
Use your function `ppDm()` to check your result in Ex 5.1.1 (single test with positive result) and Ex 5.1.2 (repeated test with one positive and one negative result).  

# Solution 5.1.4  
```{r ex5.1.4a}
tr <- 1
tpr <- 0.99
fpr <- 0.05
prior <- 0.001
post3 <- ppDm(tr=tr, tpr=tpr, fpr=fpr, prior=prior)    
```  

As in Ex 5.1.1, the test has true positive rate `r tpr*100`% and false positive rate `r fpr*100`% for a disease with prior probability `r prior*100`%. Given a `r ifelse(tr, "positive", "negative")` test result, the posterior probability of disease, calculated using our new function `ppDm()`, is `r post3*100`%, in agreement with Ex 5.1.1.  

```{r ex5.1.4b}
tr <- c(1, 0)
post4 <- ppDm(tr=tr, tpr=tpr, fpr=fpr, prior=prior)    
```  
Using our new function `ppDm()`, the probability of disease given one positive test result and one negative test result is `r post4*100`%, in agreement with Ex 5.1.2.    

# Ex 5.4  
(based loosely on Ex 5.4, on page 120 of our text) (15 points)  
Write a chunk that makes a 3 by 2 matrix of plots in the style of Figures 5.1-3 in our text. In the left column, use a vague prior and an informative Bernoulli likelihood (`Z=10`, `N=40`); in the right column use an informative prior and a vague Bernoulli likelihood (`Z=1`, `N=4`). Don't bother putting the HDIs on the plots. Use Kruschke's `BernGridExample.R` and `BernGrid.R` for inspiration, but do not `source()` any of his scripts.  

## Suggestions    

1. Use $\theta$ in your axis labels but save typing by using `x` instead of `theta` in your code.  

2. Use Kruschke's "triangle" function `y <- pmin(x,1-x)^a` or R's `dbeta(x,shape1,shape2)` for your priors.  

3. Scale your likelihood by using `y <- 0.45*y/max(y)`.  

4. Scale your prior and posterior by using either `y <- y/sum(y)` (the [Dirac comb](https://en.wikipedia.org/wiki/Dirac_comb) approximation used by Kruschke) or `y <- y/trap(x,y)` (the piecewise linear approximation) where `trap()` is a function that returns the integral of `y` over its whole domain, calculated by the [trapezoidal-rule](https://en.wikipedia.org/wiki/Trapezoidal_rule):  

```
trap <- function(x,y)  # integral of y from x[1] to x[length(x)]  
          sum( diff(x)*0.5*( y[-1] + y[-length(y)] ) )  
```

# Solution 5.4  

```{r ex5.4, fig.align="center", fig.asp=0.7, fig.width=6, fig.cap="**Figure 5.4:** In the left column the prior is vague and the likelihood is informative, and in the right column the situation is reversed."}
par(mfcol=c(3, 2),          # 3x2 matrix of plots
    mar=c(3.5, 4.1, 2, 1),  # inner margins
    mgp=c(2.0, 1, 0)        # put labels nearer axes
   )
trap <- function(x, y) # integral of y from x[1] to x[length(x)]
  sum(diff(x)*0.5*(y[-1] + y[-length(y)]))

trngl <- function(x, power) {
  y <- pmin(x, 1-x)^power 
  y/trap(x, y)
}

BernLike <- function(x, Z, N) {
  f <- x^Z*(1-x)^(N-Z)
  0.45*f/max(f)
}

post <- function(x, prior, like) {
  f <- prior*like 
  f/trap(x, f)
}

panel <- function(x, y, title, Z=NULL, N=NULL) {
  if (title=="Prior") {
    ylab <- expression(p(theta))
  } else if (title=="Likelihood") {
    ylab <- expression(p(D*"|"*theta))
  } else { # Posterior
    ylab <- expression(p(theta*"|"*D))
  }
  plot(x, y, type="n", ylim=c(0, 1.1*max(y)), 
       xlab = expression(theta), cex.lab=1.1,
       ylab = ylab, 
       main = title)
  xp <- c(        x         , rev(x) )
  yp <- c( rep(0, length(x)), rev(y) )
  polygon(xp, yp, col="skyblue", border=NA)
  mode  <- x[which.max(y)]
  if (title=="Likelihood") {
    line1 <- bquote("Data: Z="*.(Z)*", N="*.(N))
    line2 <- bquote("mode="*.(mode))
    text(0.7 , 0.90*max(y), line1)
    text(0.75, 0.75*max(y), line2)
  } else {
    line1 <- bquote("mode="*.(mode))
    text(0.7 , 0.9*max(y), line1)
  }
  return(invisible(NULL))
}

x <- seq(0, 1, len=201)

prior <- trngl(x, power=0.1) 
panel(x, prior, title="Prior") # (1,1)

like  <- BernLike(x, Z=10, N=40)
panel(x, like, title="Likelihood", Z=10, N=40) # (2,1)

f <- post(x, prior=prior, like=like)
panel(x, f, title="Posterior") # (3,1)

prior <- trngl(x, power=6) 
panel(x, prior, title="Prior") # (1,2)

like  <- BernLike(x, Z=1, N=4)
panel(x, like, title="Likelihood", Z=1, N=4) # (2,2)

f <- post(x, prior=prior, like=like)
panel(x, f, title="Posterior") # (3,2)
```  

# Ex 5.5  
(not in text) (10 points)  

This problem will give you a bit of practise using samples, something we spoke of in our first few meetings: (a) Use `rbeta()` to generate 2,000 samples of $\theta$ from the beta distribution with shape parameters `a=2` and `b=3`; use `set.seed(123)` in your chunk to ensure that we all use the same set of pseudo-random numbers and thus get the same answer. (b) Use your samples to calculate $\Pr(\theta < 0.75\, \vert\, \theta > 0.5)$. (c) Check your result using `pbeta()`. Give your answers in narrative using inline code.   

# Solution 5.5  
```{r ex5.5}
## using x for theta to save typing. SO lazy!
set.seed(123)
N <- 2000 # number of samples
a <- 2; b <- 3 # shape parameters
x <- rbeta(N, a, b) # samples
N1 <- sum(x < 0.75 & x > 0.5)
N2 <- sum(x > 0.5)
Pb <- N1/N2

Pc <- (pbeta(0.75,a,b) - pbeta(0.5,a,b)) / 
           (1 - pbeta(0.5,a,b))
```  
Using `r N` samples from a beta distribution with shape parameters a = `r a` and b = `r b`, we find that $\Pr(\theta \lt 0.75\, \vert\, \theta \gt 0.5) =$ `r Pb`. The exact value of this probability, calculated using `pbeta()` is `r Pc`.  

# Ex 5.6  

(Not in text) (15 points)  
In order to code a Gibbs sampler (GS) you must be able to make any positive 1-D function into a PDF and sample from it. (As you will learn in class, and in Chapter 7 of our text, the Gibbs sampler works by taking a draw from each parameter, holding the other parameters temporarily fixed. The multidimensional posterior thus become a 1-D function of the parameter currently being "visited".) This exercise is an introduction to GS coding.  

Suppose the `(d,p,q,r)beta` quartet of functions is not supplied by R and you have to write your own. This exercise is to write `dmb()`, your own version of `dbeta()`. Think "d-my-beta". In the next assignment, we'll complete the quartet by writing `pmb()`, `qmb()` and `rmb()`.   

Write `dmb(x, a=1, b=1, Ni=301)` which makes $f(\theta,a,b)=\theta^{a-1}(1-\theta)^{b-1}$ into a PDF using `Ni` points to compute the integral. Give a partial check of your work by graphing `dmb(x,a=2,b=4,Ni=201)` against `dbeta(x, shape1=2, shape2=4)` for `x <- seq(0,1,len=101)`, fitting a line with `lm()` and making a histogram of the residuals. Put the two plots side by side in the same figure with the histogram in the right panel.    

**Hints:** A PDF has to integrate to 1, so divide $f(\theta,a,b)$ by its integral from 0 to 1 to make it a PDF. You can use `integrate()` if you like, but remember that in MCMC you might call this function 100,000 times; for greater speed you might consider using the trapezoidal rule: `sum( diff(xi)*0.5*(fi[-1] + fi[-Ni]) )`, in which `Ni` is the number of points used to compute `xi` and `fi`; do not confuse the `xi` with the `dmb()` argument `x`. In the left panel of your figure use `xlab=bquote("dbeta("*a==.(a)*","~b==.(b)*")")` and `ylab=bquote("dmb("*a==.(a)*","~b==.(b)*")")`.    

## Solution 5.6  
Here is a chunk to make `dmb(x, a=1, b=1, Ni=301)`.  
```{r ex5.6A1}
dmb <- function(x, a=1, b=1, Ni=301) {
  ## In the interests of speed, arguments are not checked!!
  # a,b:  shape parameters
  # Ni: the number of points to use for the integral
  xi  <- seq(0, 1, len=Ni)
  fi   <- xi^(a-1)*(1-xi)^(b-1)
  int <- sum( diff(xi)*0.5*(fi[-1] + fi[-Ni]) ) 
  return( x^(a-1)*(1-x)^(b-1)/int )
}
```  

And here is a chunk to test it.  
```{r ex6.5A2, fig.asp=0.5, fig.cap="**Figure 5.6.** Testing `dmb()` our home-made version of `dbeta()`. The left panel graphs `dmb()` against `dbeta()` and the right panel shows the residuals. As the residuals are on the order of 10^-15^, our `dmb()` does very well---for these shape parameters."}  
par(mgp=c(2.5, 1, 0), mar=c(4.5, 4, 1, 1), mfrow=c(1, 2))

a <- 2; b <- 4
Nx <- 101
x  <- seq(0, 1, len=Nx)
y2 <- dmb(x, a=a, b=b)
y1 <- dbeta(x, shape1=a, shape2=b)

## left panel
plot(y1, y2, type="p", bty="l",
     xlab=bquote("dbeta("*a==.(a)*","~b==.(b)*")"),
     ylab=bquote("dmb("  *a==.(a)*","~b==.(b)*")")
     )

fit <- lm(y2~y1)
abline(fit, col="red")

legend("topleft", inset=0.05, bty="n",
       lty=c(NA, 1), col=c("black", "red"),
       pch=c(1, NA), legend=c("data", "fit")
       )

## right panel
hist(fit$residuals, main="")
```  
Our `dmb()` passed its test with flying colors, but we should remember that the beta function is very smooth for small shape parameters. If the shape parameters were large it would be much more concentrated near its mode(s), and a large N would be needed to capture the behavior near the mode(s).   



