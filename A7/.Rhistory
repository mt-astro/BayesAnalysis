abline(v=as.vector(HDI95), lwd=3., col="blue")
legend(-0.1, 125, legend=c("E[x]", "95% HDI"), lwd=3., col=c("red", "blue"))
plot(sorted_samples, sampleCDF)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
abline(h=c(0.025, 1-0.025), lwd=2., col="green")
#given info
Nsample = 2000
N1 = 50
H1 = 35
T1 = N1 - H1
N2 = 40
H2 = 18
T2 = N2-H2
#ensuing calculations assume the distribution of phi is normal and the stddev of the
# normal distribtion is a valid measurement of the deviations
sample1 = rbeta(Nsample, H1,T1)
sample2 = rbeta(Nsample, H2, T2)
phi_samples = sample1 - sample2
hist_out = hist(phi_samples, sqrt(Nsample), plot=FALSE)
phi_expect = sum(hist_out$mids * hist_out$counts) / sum(hist_out$counts)
phi_centered = phi_samples - phi_expect
phi_stddev = sqrt(var(phi_centered))
# we could compute a gaussian 95% HDI assuming 95% CI = 2 x stddev
# but good practice for computing the CDF
#super inefifcient way to compute
sorted_samples = sort(phi_samples) + 1.0
sampleCDF = cumsum(sorted_samples) / max(cumsum(sorted_samples))
HDI95 = approx(sampleCDF, sorted_samples, c(0.025, 1.0-0.025))$y - 1.
point1_idx = phi_samples > -0.1 & phi_samples < 0.1
point1_frac = sum(point1_idx) / Nsample
# plotting!
hist(phi_samples, sqrt(Nsample), density=10, plot=TRUE)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
legend(-0.1, 125, legend=c("E[x]", "95% HDI"), lwd=3., col=c("red", "blue"))
plot(sorted_samples-1, sampleCDF)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
abline(h=c(0.025, 1-0.025), lwd=2., col="green")
#given info
Nsample = 2000
N1 = 50
H1 = 35
T1 = N1 - H1
N2 = 40
H2 = 18
T2 = N2-H2
#ensuing calculations assume the distribution of phi is normal and the stddev of the
# normal distribtion is a valid measurement of the deviations
sample1 = rbeta(Nsample, H1,T1)
sample2 = rbeta(Nsample, H2, T2)
phi_samples = sample1 - sample2
hist_out = hist(phi_samples, sqrt(Nsample), plot=FALSE)
phi_expect = sum(hist_out$mids * hist_out$counts) / sum(hist_out$counts)
phi_centered = phi_samples - phi_expect
phi_stddev = sqrt(var(phi_centered))
# we could compute a gaussian 95% HDI assuming 95% CI = 2 x stddev
# but good practice for computing the CDF
#super inefifcient way to compute
sorted_samples = sort(phi_samples) + 10.0
sampleCDF = cumsum(sorted_samples) / max(cumsum(sorted_samples))
HDI95 = approx(sampleCDF, sorted_samples, c(0.025, 1.0-0.025))$y - 10.
point1_idx = phi_samples > -0.1 & phi_samples < 0.1
point1_frac = sum(point1_idx) / Nsample
# plotting!
hist(phi_samples, sqrt(Nsample), density=10, plot=TRUE)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
legend(-0.1, 125, legend=c("E[x]", "95% HDI"), lwd=3., col=c("red", "blue"))
plot(sorted_samples-1, sampleCDF)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
abline(h=c(0.025, 1-0.025), lwd=2., col="green")
#given info
Nsample = 2000
N1 = 50
H1 = 35
T1 = N1 - H1
N2 = 40
H2 = 18
T2 = N2-H2
#ensuing calculations assume the distribution of phi is normal and the stddev of the
# normal distribtion is a valid measurement of the deviations
sample1 = rbeta(Nsample, H1,T1)
sample2 = rbeta(Nsample, H2, T2)
phi_samples = sample1 - sample2
hist_out = hist(phi_samples, sqrt(Nsample), plot=FALSE)
phi_expect = sum(hist_out$mids * hist_out$counts) / sum(hist_out$counts)
phi_centered = phi_samples - phi_expect
phi_stddev = sqrt(var(phi_centered))
# we could compute a gaussian 95% HDI assuming 95% CI = 2 x stddev
# but good practice for computing the CDF
#super inefifcient way to compute
shift = 1000.
sorted_samples = sort(phi_samples) + shift
sampleCDF = cumsum(sorted_samples) / max(cumsum(sorted_samples))
HDI95 = approx(sampleCDF, sorted_samples, c(0.025, 1.0-0.025))$y - shift
point1_idx = phi_samples > -0.1 & phi_samples < 0.1
point1_frac = sum(point1_idx) / Nsample
# plotting!
hist(phi_samples, sqrt(Nsample), density=10, plot=TRUE)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
legend(-0.1, 125, legend=c("E[x]", "95% HDI"), lwd=3., col=c("red", "blue"))
plot(sorted_samples-shift, sampleCDF)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
abline(h=c(0.025, 1-0.025), lwd=2., col="green")
#given info
Nsample = 2000
N1 = 50
H1 = 35
T1 = N1 - H1
N2 = 40
H2 = 18
T2 = N2-H2
#ensuing calculations assume the distribution of phi is normal and the stddev of the
# normal distribtion is a valid measurement of the deviations
sample1 = rbeta(Nsample, H1,T1)
sample2 = rbeta(Nsample, H2, T2)
phi_samples = sample1 - sample2
hist_out = hist(phi_samples, sqrt(Nsample), plot=FALSE)
phi_expect = sum(hist_out$mids * hist_out$counts) / sum(hist_out$counts)
phi_centered = phi_samples - phi_expect
phi_stddev = sqrt(var(phi_centered))
# we could compute a gaussian 95% HDI assuming 95% CI = 2 x stddev
# but good practice for computing the CDF
#super inefifcient way to compute
shift = 1000.
sorted_samples = sort(phi_samples) + shift
sampleCDF = cumsum(sorted_samples) / max(cumsum(sorted_samples))
HDI95 = approx(sampleCDF, sorted_samples, c(0.025, 1.0-0.025))$y - shift
point1_idx = phi_samples > -0.1 & phi_samples < 0.1
point1_frac = sum(point1_idx) / Nsample
# plotting!
hist(phi_samples, sqrt(Nsample), density=10, plot=TRUE)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
legend(-0.1, 125, legend=c("E[x]", "95% HDI"), lwd=3., col=c("red", "blue"))
plot(sorted_samples-shift, sampleCDF)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
abline(h=c(0.025, 1-0.025), lwd=2., col="green")
#given info
Nsample = 2000
N1 = 50
H1 = 35
T1 = N1 - H1
N2 = 40
H2 = 18
T2 = N2-H2
#ensuing calculations assume the distribution of phi is normal and the stddev of the
# normal distribtion is a valid measurement of the deviations
sample1 = rbeta(Nsample, H1,T1)
sample2 = rbeta(Nsample, H2, T2)
phi_samples = sample1 - sample2
hist_out = hist(phi_samples, sqrt(Nsample), plot=FALSE)
phi_expect = sum(hist_out$mids * hist_out$counts) / sum(hist_out$counts)
phi_centered = phi_samples - phi_expect
phi_stddev = sqrt(var(phi_centered))
# we could compute a gaussian 95% HDI assuming 95% CI = 2 x stddev
# but good practice for computing the CDF
#super inefifcient way to compute
shift = min(phi_samples)
sorted_samples = sort(phi_samples) + shift
sampleCDF = cumsum(sorted_samples) / max(cumsum(sorted_samples))
HDI95 = approx(sampleCDF, sorted_samples, c(0.025, 1.0-0.025))$y - shift
point1_idx = phi_samples > -0.1 & phi_samples < 0.1
point1_frac = sum(point1_idx) / Nsample
# plotting!
hist(phi_samples, sqrt(Nsample), density=10, plot=TRUE)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
legend(-0.1, 125, legend=c("E[x]", "95% HDI"), lwd=3., col=c("red", "blue"))
plot(sorted_samples-shift, sampleCDF)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
abline(h=c(0.025, 1-0.025), lwd=2., col="green")
#given info
Nsample = 2000
N1 = 50
H1 = 35
T1 = N1 - H1
N2 = 40
H2 = 18
T2 = N2-H2
#ensuing calculations assume the distribution of phi is normal and the stddev of the
# normal distribtion is a valid measurement of the deviations
sample1 = rbeta(Nsample, H1,T1)
sample2 = rbeta(Nsample, H2, T2)
phi_samples = sample1 - sample2
hist_out = hist(phi_samples, sqrt(Nsample), plot=FALSE)
phi_expect = sum(hist_out$mids * hist_out$counts) / sum(hist_out$counts)
phi_centered = phi_samples - phi_expect
phi_stddev = sqrt(var(phi_centered))
# we could compute a gaussian 95% HDI assuming 95% CI = 2 x stddev
# but good practice for computing the CDF
#super inefifcient way to compute
#shift values to strictly positive for CDF computational
shift = abs(min(phi_samples))
sorted_samples = sort(phi_samples) + shift
sampleCDF = cumsum(sorted_samples) / max(cumsum(sorted_samples))
HDI95 = approx(sampleCDF, sorted_samples, c(0.025, 1.0-0.025))$y - shift
point1_idx = phi_samples > -0.1 & phi_samples < 0.1
point1_frac = sum(point1_idx) / Nsample
# plotting!
hist(phi_samples, sqrt(Nsample), density=10, plot=TRUE)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
legend(-0.1, 125, legend=c("E[x]", "95% HDI"), lwd=3., col=c("red", "blue"))
plot(sorted_samples-shift, sampleCDF)
abline(v=phi_expect, lwd=3., col="red")
abline(v=as.vector(HDI95), lwd=3., col="blue")
abline(h=c(0.025, 1-0.025), lwd=2., col="green")
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", legnth=Nsample)
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
new_post = evalPost(new_theta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
new_post = evalPost(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
hist(theta_values, plot=TRUE)
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
new_post = evalPost(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
hist(computed_post, plot=TRUE)
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
new_post = evalPost(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
plot(theta_values, computed_post)
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
if (newtheta) < 0.0: newtheta=0.0
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
if (newtheta < 0.0): newtheta=0.0
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
if (newtheta < 0.0) newtheta=0.0
if (newtheta > 1.0) newtheta=1.0
new_post = evalPost(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
plot(theta_values, computed_post)
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
if (newtheta < 0.0) newtheta=0.0
if (newtheta > 1.0) newtheta=1.0
new_post = evalPost(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
hist(theta_values)
plot(theta_values, computed_post)
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
if (newtheta < 0.0) newtheta=0.0
if (newtheta > 1.0) newtheta=1.0
new_post = evalLikelihood(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
hist(theta_values)
plot(theta_values, computed_post)
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
parfF_samp = approx(sorted_post, postCDF, c(0.2, 0.5))
partF_ans = partF_samp[2] - partF_samp[1]
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
partF_samp = approx(sorted_post, postCDF, c(0.2, 0.5))
partF_ans = partF_samp[2] - partF_samp[1]
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
plot(sorted_post, postCDF)
partF_samp = approx(sorted_post, postCDF, c(0.2, 0.5))
partF_ans = partF_samp[2] - partF_samp[1]
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = sort(theta_values)
plot(sorted_post, postCDF)
partF_samp = approx(theta_values, postCDF, c(0.2, 0.5))
partF_ans = partF_samp[2] - partF_samp[1]
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = sort(theta_values)
plot(theta_values, postCDF)
partF_samp = approx(theta_values, postCDF, c(0.2, 0.5))
partF_ans = partF_samp[2] - partF_samp[1]
partF_samp
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = seq(0, 1, by=1/length(postCDF))
plot(theta_values, postCDF)
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = seq(0, 1, length=length(postCDF))
plot(theta_values, postCDF)
partF_samp = approx(theta_values, postCDF, c(0.2, 0.5))$y
partF_ans = partF_samp[2] - partF_samp[1]
partG_wide = approx(theta_values, postCDF, c(0.1, 0.8))$y
partG_narrow = approx(theta_values, postCDF, c(0.3, 0.4))
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = seq(0, 1, length=length(postCDF))
plot(sorted_post, postCDF)
partF_samp = approx(theta_values, postCDF, c(0.2, 0.5))$y
partF_ans = partF_samp[2] - partF_samp[1]
partG_wide = approx(theta_values, postCDF, c(0.1, 0.8))$y
partG_narrow = approx(theta_values, postCDF, c(0.3, 0.4))
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = seq(0, 1, length=length(postCDF))
plot(theta_values, postCDF)
partF_samp = approx(theta_values, postCDF, c(0.2, 0.5))$y
partF_ans = partF_samp[2] - partF_samp[1]
partG_wide = approx(theta_values, postCDF, c(0.1, 0.8))$y
partG_narrow = approx(theta_values, postCDF, c(0.3, 0.4))
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
sorted_post
theta_values
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = seq(0, 1, length=length(postCDF))
plot(theta_values, postCDF)
partF_samp = approx(theta_values, postCDF, c(0.2, 0.5))$y
partF_ans = partF_samp[2] - partF_samp[1]
partG_wide = approx(theta_values, postCDF, c(0.1, 0.8))$y
partG_narrow = approx(theta_values, postCDF, c(0.3, 0.4))$y
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
partF_samp
theta_values
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = seq(0, 1, length=length(postCDF))
plot(theta_values, postCDF)
partF_samp = approx(sorted_post, postCDF, c(0.2, 0.5))$y
partF_ans = partF_samp[2] - partF_samp[1]
partG_wide = approx(theta_values, postCDF, c(0.1, 0.8))$y
partG_narrow = approx(theta_values, postCDF, c(0.3, 0.4))$y
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
sorted_post = sort(computed_post)
postCDF = cumsum(sorted_post) / max(cumsum(sorted_post))
theta_values = seq(0, 1, length=length(postCDF))
plot(sorted_post, postCDF)
partF_samp = approx(sorted_post, postCDF, c(0.2, 0.5))$y
partF_ans = partF_samp[2] - partF_samp[1]
partG_wide = approx(theta_values, postCDF, c(0.1, 0.8))$y
partG_narrow = approx(theta_values, postCDF, c(0.3, 0.4))$y
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
partF_idx = theta_values <= 0.5 & theta_values >= 0.2
partF_ans = sum(computed_post[partF_idx]) / sum(computed_post)
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
partF_ans
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
partF_idx = theta_values <= 0.5 & theta_values >= 0.2
partF_ans = 1.0 - sum(computed_post[partF_idx]) / sum(computed_post)
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
partF_ans
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
partF_idx = theta_values <= 0.5 & theta_values >= 0.2
partF_ans = 1.0 - sum(partF_idx) / Nsample
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
partF_ans
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
partF_idx = theta_values <= 0.5 & theta_values >= 0.2
partF_ans = sum(partF_idx) / Nsample
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
partF_ans
sum(computed_post)
partF_idx
plot(theta_values[partF_idx], computed_post[partF_idx])
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
if (newtheta < 0.0) newtheta=0.0
if (newtheta > 1.0) newtheta=1.0
new_post = evalPost(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
plot(theta_values, computed_post)
theta = 0.5
computed_post = vector(mode="numeric", length=Nsample)
theta_values = vector(mode="numeric", length=Nsample)
for (i in 1:Nsample){
newtheta = rnorm(1, theta, SD)
if (newtheta < 0.0) newtheta=0.0
if (newtheta > 1.0) newtheta=1.0
new_post = evalPost(newtheta)
theta_values[i] = newtheta
computed_post[i] = new_post
theta = newtheta
}
plot(theta_values, computed_post)
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
partF_idx = theta_values <= 0.5 & theta_values >= 0.2
partF_ans = sum(partF_idx) / Nsample
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
partF_idx = theta_values <= 0.5 & theta_values >= 0.2
partF_ans = sum(partF_idx) / Nsample
partG_ans = (partG_narrow[2] - partG_narrow[1]) / (partG_wide[2]-partG_wide[1])
print(partG_ans)
plot(theta_values[partF_idx], computed_post[partF_idx])
partF_ans
sum(computed_post[partF_idx])
sum(computed_post[partF_idx]) / sum(computed_post)
#compute CDF from posterior values
# even if this is the wrong approach, its practice computing CDF
partF_idx = theta_values <= 0.5 & theta_values >= 0.2
partF_ans = sum(computed_post[partF_idx]) / sum(computed_post)
wide_idx = theta_values <= 0.8 & theta_values >= 0.1
narrow_idx = theta_values <= 0.4 & theta_values >= 0.3
wide_sum = sum(computed_post[wide_idx])
narrow_sum = sum(computed_post[narrow_idx])
partG_ans = narrow_sum / wide_sum
print(partG_ans)
